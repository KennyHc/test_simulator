<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ML II Mastery Quiz - Dark Mode</title>
    <style>
        :root {
            --bg-body: #0f172a;       /* Deep Slate */
            --bg-card: #1e293b;       /* Slate 800 */
            --text-main: #f1f5f9;     /* Slate 100 */
            --text-muted: #94a3b8;    /* Slate 400 */
            
            --accent-gradient: linear-gradient(135deg, #3b82f6 0%, #8b5cf6 100%); /* Blue to Purple */
            --progress-gradient: linear-gradient(90deg, #06b6d4 0%, #3b82f6 50%, #8b5cf6 100%); /* Cyan to Purple */
            
            --success-bg: #064e3b;
            --success-border: #10b981;
            --success-text: #d1fae5;
            
            --error-bg: #450a0a;
            --error-border: #ef4444;
            --error-text: #fee2e2;

            --option-bg: #334155;
            --option-hover: #475569;
        }

        body {
            font-family: 'Segoe UI', Roboto, Helvetica, Arial, sans-serif;
            background-color: var(--bg-body);
            color: var(--text-main);
            margin: 0;
            padding: 0;
            min-height: 100vh;
            display: flex;
            align-items: center;
            justify-content: center;
        }

        .container {
            width: 100%;
            max-width: 750px;
            background: var(--bg-card);
            padding: 40px;
            border-radius: 24px;
            box-shadow: 0 25px 50px -12px rgba(0, 0, 0, 0.5);
            position: relative;
            overflow: hidden;
            margin: 20px;
        }

        /* Header & Progress */
        header {
            margin-bottom: 30px;
            text-align: center;
        }

        h1 {
            margin: 0 0 20px 0;
            font-weight: 800;
            background: var(--accent-gradient);
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
            font-size: 2rem;
            letter-spacing: -0.02em;
        }

        .progress-container {
            background: #0f172a;
            height: 12px;
            border-radius: 20px;
            overflow: hidden;
            position: relative;
            margin-bottom: 20px;
        }

        .progress-fill {
            height: 100%;
            width: 0%;
            background: var(--progress-gradient);
            border-radius: 20px;
            transition: width 0.5s cubic-bezier(0.4, 0, 0.2, 1);
            box-shadow: 0 0 10px rgba(59, 130, 246, 0.5);
        }

        /* Score Tracker */
        .score-board {
            display: flex;
            justify-content: center;
            gap: 20px;
            margin-bottom: 30px;
            font-size: 0.9rem;
            font-weight: 600;
        }

        .score-pill {
            padding: 8px 16px;
            border-radius: 12px;
            display: flex;
            align-items: center;
            gap: 8px;
            background: #0f172a;
            border: 1px solid #334155;
        }

        .score-pill.correct span { color: #10b981; }
        .score-pill.wrong span { color: #ef4444; }

        /* Question Area */
        .question-card {
            margin-bottom: 30px;
        }

        .question-text {
            font-size: 1.25rem;
            line-height: 1.5;
            margin-bottom: 25px;
            font-weight: 600;
        }

        .options-grid {
            display: grid;
            gap: 15px;
        }

        .option-btn {
            background: var(--option-bg);
            color: var(--text-main);
            border: 2px solid transparent;
            padding: 16px 20px;
            border-radius: 16px;
            text-align: left;
            font-size: 1rem;
            cursor: pointer;
            transition: all 0.3s cubic-bezier(0.4, 0, 0.2, 1);
            position: relative;
        }

        .option-btn:hover:not(:disabled) {
            background: var(--option-hover);
            transform: translateY(-3px) scale(1.01);
            box-shadow: 0 10px 15px -3px rgba(0, 0, 0, 0.3);
            border-color: #64748b;
        }

        .option-btn:active:not(:disabled) {
            transform: translateY(-1px);
        }

        .option-btn.correct {
            background: var(--success-bg);
            border-color: var(--success-border);
            color: var(--success-text);
            box-shadow: 0 0 15px rgba(16, 185, 129, 0.2);
        }

        .option-btn.incorrect {
            background: var(--error-bg);
            border-color: var(--error-border);
            color: var(--error-text);
            opacity: 0.8;
        }

        .option-btn:disabled {
            cursor: default;
        }

        /* Feedback Section */
        .feedback {
            margin-top: 25px;
            padding: 20px;
            border-radius: 16px;
            background: #334155;
            border-left: 4px solid var(--text-muted);
            display: none;
            animation: slideDown 0.4s ease;
        }

        @keyframes slideDown {
            from { opacity: 0; transform: translateY(-10px); }
            to { opacity: 1; transform: translateY(0); }
        }

        /* Footer Controls */
        .controls {
            margin-top: 30px;
            display: flex;
            justify-content: space-between;
            align-items: center;
            border-top: 1px solid #334155;
            padding-top: 20px;
        }

        .q-count {
            color: var(--text-muted);
            font-size: 0.9rem;
        }

        .primary-btn {
            background: var(--accent-gradient);
            color: white;
            border: none;
            padding: 12px 30px;
            border-radius: 12px;
            font-weight: 700;
            font-size: 1rem;
            cursor: pointer;
            transition: opacity 0.2s;
            box-shadow: 0 4px 6px -1px rgba(0, 0, 0, 0.1);
        }

        .primary-btn:hover:not(:disabled) {
            opacity: 0.9;
            transform: translateY(-1px);
        }

        .primary-btn:disabled {
            background: #475569;
            color: #94a3b8;
            cursor: not-allowed;
            box-shadow: none;
        }

        /* Results Screen */
        .result-screen {
            text-align: center;
            display: none;
            padding: 20px;
        }

        .final-score {
            font-size: 4rem;
            font-weight: 900;
            margin: 20px 0;
            background: var(--progress-gradient);
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
        }

        .score-message {
            font-size: 1.2rem;
            color: var(--text-muted);
            margin-bottom: 30px;
        }

    </style>
</head>
<body>

<div class="container">
    <div id="quiz-screen">
        <header>
            <h1>ML II Mastery Quiz</h1>
            <div class="progress-container">
                <div class="progress-fill" id="progress"></div>
            </div>
            
            <div class="score-board">
                <div class="score-pill correct">
                    <svg xmlns="http://www.w3.org/2000/svg" width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="#10b981" stroke-width="3" stroke-linecap="round" stroke-linejoin="round"><polyline points="20 6 9 17 4 12"></polyline></svg>
                    <span id="score-correct">0</span> Correct
                </div>
                <div class="score-pill wrong">
                    <svg xmlns="http://www.w3.org/2000/svg" width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="#ef4444" stroke-width="3" stroke-linecap="round" stroke-linejoin="round"><line x1="18" y1="6" x2="6" y2="18"></line><line x1="6" y1="6" x2="18" y2="18"></line></svg>
                    <span id="score-wrong">0</span> Wrong
                </div>
            </div>
        </header>

        <div class="question-card">
            <div class="question-text" id="question-text">Question text goes here...</div>
            <div class="options-grid" id="options-container">
                </div>
        </div>

        <div class="feedback" id="feedback"></div>

        <div class="controls">
            <span class="q-count" id="question-number">Question 1 of 20</span>
            <button id="next-btn" class="primary-btn" onclick="nextQuestion()" disabled>Next Question</button>
        </div>
    </div>

    <div id="result-screen" class="result-screen">
        <h1>Quiz Complete!</h1>
        <p style="color: var(--text-muted);">You scored</p>
        <div class="final-score" id="final-score-display">0/20</div>
        <div class="score-board" style="margin-bottom: 10px;">
             <div class="score-pill correct"><span id="final-correct">0</span> Correct</div>
             <div class="score-pill wrong"><span id="final-wrong">0</span> Wrong</div>
        </div>
        <p class="score-message" id="score-message">Performance Message</p>
        <button class="primary-btn" onclick="restartQuiz()">Retake Quiz</button>
    </div>
</div>

<script>
    const questions = [
        {
            q: "In Association Analysis, what does the 'Apriori Principle' state?",
            options: [
                "If an itemset is infrequent, its subsets must be frequent.",
                "If an itemset is frequent, all its subsets must also be frequent.",
                "The confidence of a rule is always greater than its support.",
                "High lift implies low confidence."
            ],
            correct: 1,
            explanation: "The Apriori Principle states that if an itemset is frequent, then all of its subsets must also be frequent, which allows for pruning the search space."
        },
        {
            q: "Which metric in Association Analysis measures the strength of a rule independent of the consequent's popularity?",
            options: ["Support", "Confidence", "Lift", "Frequency"],
            correct: 2,
            explanation: "Lift compares the rule's confidence to the expected confidence if the antecedent and consequent were independent."
        },
        {
            q: "In Decision Trees, which metric is used by the CART algorithm to measure node impurity?",
            options: ["Entropy", "Information Gain", "Gini Index", "Root Mean Square Error"],
            correct: 2,
            explanation: "CART (Classification and Regression Trees) uses the Gini Index to measure impurity. ID3/C4.5 use Entropy."
        },
        {
            q: "What is the primary purpose of 'Pruning' in Decision Trees?",
            options: [
                "To increase the bias of the model.",
                "To reduce the variance and prevent overfitting.",
                "To increase the number of terminal nodes.",
                "To calculate the Information Gain."
            ],
            correct: 1,
            explanation: "Pruning removes branches that provide little power to classify instances, thereby reducing complexity and high variance (overfitting)."
        },
        {
            q: "Which ensemble method focuses primarily on reducing Bias by fitting models sequentially on residuals?",
            options: ["Bagging", "Random Forest", "Bootstrapping", "Boosting"],
            correct: 3,
            explanation: "Boosting trains models sequentially, where each new model attempts to correct the errors (residuals) of the previous ones."
        },
        {
            q: "How does Random Forest differ from standard Bagging?",
            options: [
                "It uses the entire dataset for every tree.",
                "It restricts the number of features available at each split.",
                "It uses a different cost function.",
                "It allows dependency between trees."
            ],
            correct: 1,
            explanation: "Random Forest de-correlates trees by forcing the algorithm to choose from a random subset of features at each split."
        },
        {
            q: "In the context of Bagging, what is the 'Out of Bag' (OOB) dataset?",
            options: [
                "The data used to train the model.",
                "The ~1/3 of samples not chosen in a bootstrap sample.",
                "The test set provided by the client.",
                "The data with missing values."
            ],
            correct: 1,
            explanation: "Because bootstrapping samples with replacement, approximately 1/3 of data is left out (OOB) and can be used for validation."
        },
        {
            q: "What is the fundamental assumption of the Na√Øve Bayes classifier?",
            options: [
                "All features are dependent on each other.",
                "Features are independent given the class.",
                "The prior probability is always 0.5.",
                "The data must be normally distributed."
            ],
            correct: 1,
            explanation: "It is called 'Na√Øve' because it assumes that the presence of a particular feature is unrelated to the presence of any other feature."
        },
        {
            q: "Why is 'Laplace Smoothing' (Add-one) used in Na√Øve Bayes?",
            options: [
                "To handle continuous variables.",
                "To avoid zero probabilities for unseen features.",
                "To reduce the computational complexity.",
                "To increase the weight of prior probabilities."
            ],
            correct: 1,
            explanation: "Laplace smoothing ensures that if a word/feature was not seen in training, the probability calculation doesn't become zero."
        },
        {
            q: "Which of the following is a characteristic of 'Lazy Learning' algorithms like KNN?",
            options: [
                "They build an explicit model during the training phase.",
                "They are computationally expensive during the training phase.",
                "They defer computation until a classification query is made.",
                "They are insensitive to outliers."
            ],
            correct: 2,
            explanation: "KNN is lazy because it stores the training data and performs calculations only when a prediction is requested."
        },
        {
            q: "In KNN, what is the effect of choosing a very small value for k (e.g., k=1)?",
            options: [
                "High Bias and Low Variance.",
                "Low Bias and High Variance (Overfitting).",
                "The model becomes a linear classifier.",
                "The model ignores local data structure."
            ],
            correct: 1,
            explanation: "A small k captures noise in the training data, creating a complex decision boundary that overfits (High Variance)."
        },
        {
            q: "Why is feature scaling (normalization) critical in KNN?",
            options: [
                "It speeds up the 'lazy' learning process.",
                "KNN relies on distance calculations, sensitive to magnitude.",
                "It converts categorical data to numeric.",
                "It is required to calculate probability."
            ],
            correct: 1,
            explanation: "Without scaling, features with larger numeric ranges would dominate the distance metric, skewing results."
        },
        {
            q: "Which distance measure is generally best for high-dimensional sparse data (like text)?",
            options: ["Euclidean Distance", "Manhattan Distance", "Cosine Distance", "Hamming Distance"],
            correct: 2,
            explanation: "Cosine distance measures the angle between vectors rather than magnitude, making it ideal for sparse text vectors."
        },
        {
            q: "In Association Rules, if Support(A, B) = 0.2 and Support(A) = 0.5, what is the Confidence(A -> B)?",
            options: ["0.1", "0.4", "0.7", "2.5"],
            correct: 1,
            explanation: "Confidence = Support(A, B) / Support(A) = 0.2 / 0.5 = 0.4."
        },
        {
            q: "Which algorithm focuses on finding the hyperplane that separates classes?",
            options: ["SVM", "Decision Trees", "Na√Øve Bayes", "Apriori"],
            correct: 0,
            explanation: "Support Vector Machines (SVM) aim to find the optimal hyperplane that separates classes with the maximum margin."
        },
        {
            q: "Which ensemble technique allows for parallel processing because trees are built independently?",
            options: ["Gradient Boosting", "Bagging / Random Forest", "AdaBoost", "XGBoost"],
            correct: 1,
            explanation: "In Bagging/RF, trees are trained on bootstrap samples independently, whereas Boosting is sequential and cannot be easily parallelized."
        },
        {
            q: "Which model is best when 'model intelligibility' (interpretability) is important?",
            options: ["Neural Networks", "Boosting", "Decision Trees", "KNN"],
            correct: 2,
            explanation: "Decision Trees are highly interpretable as they provide clear if-then rules that mimic human decision-making."
        },
        {
            q: "What is the 'Curse of Dimensionality' in the context of KNN?",
            options: [
                "KNN becomes too fast with many features.",
                "Distance measures become less meaningful as features increase.",
                "The value of k must equal the number of dimensions.",
                "It refers to the difficulty of visualizing the data."
            ],
            correct: 1,
            explanation: "In high dimensions, data becomes sparse and all points tend to be equidistant, making nearest neighbor search ineffective."
        },
        {
            q: "In a Decision Tree, what does a 'Leaf Node' represent?",
            options: ["A decision rule.", "The root of the tree.", "A final class assignment or value.", "A splitting feature."],
            correct: 2,
            explanation: "Leaf nodes are the terminal nodes of the tree where the final prediction (class or regression value) is made."
        },
        {
            q: "If a specific association rule has a Lift of 1, what does this imply?",
            options: [
                "Strong positive correlation.",
                "Strong negative correlation.",
                "The antecedent and consequent are independent.",
                "The rule is invalid."
            ],
            correct: 2,
            explanation: "Lift = 1 implies that the probability of occurrence of the antecedent and consequent together is exactly the same as if they were independent events."
        }
    ];

    let currentQuestion = 0;
    let correctCount = 0;
    let wrongCount = 0;
    let answered = false;

    function initQuiz() {
        correctCount = 0;
        wrongCount = 0;
        currentQuestion = 0;
        updateScoreDisplay();
        renderQuestion();
        document.getElementById('result-screen').style.display = 'none';
        document.getElementById('quiz-screen').style.display = 'block';
    }

    function updateScoreDisplay() {
        document.getElementById('score-correct').textContent = correctCount;
        document.getElementById('score-wrong').textContent = wrongCount;
    }

    function renderQuestion() {
        answered = false;
        const q = questions[currentQuestion];
        document.getElementById('question-text').textContent = q.q;
        document.getElementById('question-number').textContent = `Question ${currentQuestion + 1} of ${questions.length}`;
        
        // Update gradient progress
        const progressPct = ((currentQuestion) / questions.length) * 100;
        document.getElementById('progress').style.width = `${progressPct}%`;

        const optsContainer = document.getElementById('options-container');
        optsContainer.innerHTML = '';

        q.options.forEach((opt, index) => {
            const btn = document.createElement('button');
            btn.className = 'option-btn';
            btn.textContent = opt;
            btn.onclick = () => checkAnswer(index, btn);
            optsContainer.appendChild(btn);
        });

        const feedbackEl = document.getElementById('feedback');
        feedbackEl.style.display = 'none';
        feedbackEl.className = 'feedback';
        
        const nextBtn = document.getElementById('next-btn');
        nextBtn.disabled = true;
        nextBtn.textContent = currentQuestion === questions.length - 1 ? "See Results" : "Next Question";
    }

    function checkAnswer(selectedIndex, btnElement) {
        if (answered) return;
        answered = true;

        const q = questions[currentQuestion];
        const buttons = document.querySelectorAll('.option-btn');
        const feedbackEl = document.getElementById('feedback');
        
        // Disable all buttons
        buttons.forEach(btn => btn.disabled = true);

        if (selectedIndex === q.correct) {
            btnElement.classList.add('correct');
            correctCount++;
            feedbackEl.style.borderLeftColor = '#10b981';
            feedbackEl.style.background = '#064e3b';
            feedbackEl.innerHTML = `<strong style="color:#34d399">Correct!</strong><br>${q.explanation}`;
        } else {
            btnElement.classList.add('incorrect');
            buttons[q.correct].classList.add('correct');
            wrongCount++;
            feedbackEl.style.borderLeftColor = '#ef4444';
            feedbackEl.style.background = '#450a0a';
            feedbackEl.innerHTML = `<strong style="color:#f87171">Incorrect.</strong><br>${q.explanation}`;
        }

        updateScoreDisplay();
        feedbackEl.style.display = 'block';
        document.getElementById('next-btn').disabled = false;
        
        // Update progress bar to show "completed" for this question
        const progressPct = ((currentQuestion + 1) / questions.length) * 100;
        document.getElementById('progress').style.width = `${progressPct}%`;
    }

    function nextQuestion() {
        if (currentQuestion < questions.length - 1) {
            currentQuestion++;
            renderQuestion();
        } else {
            showResults();
        }
    }

    function showResults() {
        document.getElementById('quiz-screen').style.display = 'none';
        document.getElementById('result-screen').style.display = 'block';
        
        document.getElementById('final-score-display').textContent = `${correctCount}/${questions.length}`;
        document.getElementById('final-correct').textContent = correctCount;
        document.getElementById('final-wrong').textContent = wrongCount;
        
        let msg = "";
        const pct = (correctCount / questions.length) * 100;
        if (pct >= 90) msg = "üèÜ Outstanding! You are a Machine Learning Master.";
        else if (pct >= 70) msg = "üéâ Great job! You have a solid grasp of the concepts.";
        else if (pct >= 50) msg = "üëç Good effort. A quick review of the summaries will help.";
        else msg = "üìö Keep learning! Review the course materials and try again.";
        
        document.getElementById('score-message').textContent = msg;
    }

    function restartQuiz() {
        initQuiz();
    }

    // Start
    initQuiz();
</script>

</body>
</html>